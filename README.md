# VQGAN-CLIP-Text-to-Image

Project is here: <a href="https://colab.research.google.com/drive/19x9kcWYC8BLIRoBQRmBIgX2GHH73KMTR?authuser=2#scrollTo=NMXe5V6nUfTo" >Link to Colab</a>
<br>
All step-by-step explanations of codes: <a href="https://budhathokisagar.com.np/blogs/6/" >Link to the post</a> <br>
<br> Read story on Medium: <a href="https://medium.com/mlearning-ai/text-to-image-synthesis-using-multimodal-vqgan-clip-architectures-fab2d243f9dd"> Link to Medium</a>
<br>
I guarantee that you'll completely understand every single steps. And completa a Advaneced GAN project.
<br>
<br>
text prompt(input): #*A man fighting with a bull*
<br> <br>
Output: After 100 epochs <br> crop: <br><img src="https://github.com/SBMagar/VQGAN-CLIP-Text-to-Image/blob/main/man-bull.png" /> </br></br> result: <br>
<img src="https://github.com/SBMagar/VQGAN-CLIP-Text-to-Image/blob/main/bull%20and%20man.jpg" />
